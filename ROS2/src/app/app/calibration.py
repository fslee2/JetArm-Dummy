#!/usr/bin/env python3
# encoding: utf-8
import os
import cv2
import time
import yaml
import rclpy
import queue
import threading
import numpy as np
import sdk.common as common
from rclpy.node import Node
from app.common import Heart
from app.utils import search_plane
from cv_bridge import CvBridge
from std_msgs.msg import Bool
from std_srvs.srv import Trigger
from dt_apriltags import Detector
from sensor_msgs.msg import Image, CameraInfo 
from kinematics_msgs.srv import GetRobotPose
from servo_controller_msgs.msg import ServosPosition
from rclpy.executors import MultiThreadedExecutor
from rclpy.callback_groups import ReentrantCallbackGroup
from servo_controller.bus_servo_control import set_servo_position
from tf2_ros import Buffer, TransformListener, TransformException

class CalibrationNode(Node):
    hand2cam_tf_matrix = [
            [0.0, 0.0, 1.0, -0.101],
            [-1.0, 0.0, 0.0, 0.0],
            [0.0, -1.0, 0.0, 0.05],
            [0.0, 0.0, 0.0, 1.0]
            ]
    
    def __init__(self, name):
        rclpy.init()
        super().__init__(name, allow_undeclared_parameters=True, automatically_declare_parameters_from_overrides=True)
        self.running = True
        self.imgpts = None
        self.imgpts1 = None
        self.plane = []
        self._init_parameters()
        self.tag_size = 0.025
        self.tag_id = [1, 2, 3]
        self.tag_id_2 = 100
        self.camera_type = os.environ['CAMERA_TYPE']
        self.chassis_type = os.environ['CHASSIS_TYPE']
        self.config_file = 'transform.yaml'
        if self.chassis_type == 'Slide_Rails':
            self.config_path = "/home/ubuntu/ros2_ws/src/stepper/config/"
        else:
            self.config_path = "/home/ubuntu/ros2_ws/src/app/config/"
        self.white_area_width = 0.167
        self.white_area_height = 0.13
        self.bridge = CvBridge()
        self.image_queue = queue.Queue(maxsize=2)
        self.depth_image_queue = queue.Queue(maxsize=2)
        # Create Publisher 创建发布者
        self.joints_pub = self.create_publisher(ServosPosition, '/servo_controller', 1)
        self.result_image_pub = self.create_publisher(Image, '~/image_result', 10)
        self.finish_pub = self.create_publisher(Bool, '~/finish', 1)

        # create service 服务
        self.create_service(Trigger, '~/enter', self.enter_srv_callback)
        self.create_service(Trigger, '~/exit', self.exit_srv_callback)
        self.create_service(Trigger, '~/start', self.start_calibration_srv_callback)

        self.at_detector = Detector(searchpath=['apriltags'],
                       families='tag36h11',
                       nthreads=4,
                       quad_decimate=1.0,
                       quad_sigma=0.0,
                       refine_edges=1,
                       decode_sharpening=0.25,
                       debug=0)
        
        tf_buffer = Buffer()
        self.tf_listener = TransformListener(tf_buffer, self)
        tf_future = tf_buffer.wait_for_transform_async(
            target_frame='depth_cam_link',
            source_frame='depth_cam_color_frame',
            time=rclpy.time.Time()
        )

        rclpy.spin_until_future_complete(self, tf_future)
        try:
            transform = tf_buffer.lookup_transform(
                'depth_cam_color_frame', 'depth_cam_link', rclpy.time.Time(),
                timeout=rclpy.duration.Duration(seconds=5.0))
            self.static_transform = transform  # save transform data 保存变换数据
            # self.get_logger().info(f'Static transform: {self.static_transform}')
        except TransformException as e:
            self.get_logger().error(f'Failed to get static transform: {e}')

        # Extract translation and rotation 提取平移和旋转
        translation = transform.transform.translation
        rotation = transform.transform.rotation

        transform_matrix = common.xyz_quat_to_mat([translation.x, translation.y, translation.z],
                                                  [rotation.w, rotation.x, rotation.y, rotation.z])
        self.hand2cam_tf_matrix = np.matmul(transform_matrix, self.hand2cam_tf_matrix)
        self.get_logger().info(f'hand2cam_tf_matrix: {self.hand2cam_tf_matrix}')
        with open(self.config_path + self.config_file, 'r') as f:
            config = yaml.safe_load(f)

            # Convert to numpy arrays 转换为 numpy 数组
            self.extristric = np.array(config['extristric'])
            self.white_area_pose_cam = np.array(config['white_area_pose_cam'])
            self.white_area_pose_world = np.array(config['white_area_pose_world'])

        threading.Thread(target=self.image_processing, daemon=True).start()

    def _init_parameters(self):
        self.thread = None
        self.err_msg = None
        self.heart = None
        self.calibration_step = 0
        self.tags = []
        self.pose = []
        self.tag_count = 0
        self.K = None
        self.D = None
        self.enter = False

        self.image_sub = None
        self.camera_info_sub = None
        self.depth_image_sub = None
        self.depth_cam_info = None
        self.depth_camera_info_sub = None


    def calibration_proc(self):
        # hand-eye calibration 手眼标定。。。。
        # calibration through fixed structural dimensions 通过固定的结构尺寸确定

        # get the current end-effector coordinates 获取当前末端坐标
        timer_cb_group = ReentrantCallbackGroup()
        self.get_current_pose_client = self.create_client(GetRobotPose, '/kinematics/get_current_pose', callback_group=timer_cb_group)
        self.get_current_pose_client.wait_for_service()
        endpoint = self.send_request(self.get_current_pose_client, GetRobotPose.Request())
        self.get_logger().info(f'endpoin11111t: {endpoint}')
        pose_t = endpoint.pose.position
        pose_r = endpoint.pose.orientation
        # self.get_logger().info(f'pose_t:{pose_t}') 
        endpoint = common.xyz_quat_to_mat([pose_t.x, pose_t.y, pose_t.z], [pose_r.w, pose_r.x, pose_r.y, pose_r.z])
            
        # get tag data 获取标签数据
        t = time.time()
        self.tags = []
        self.calibration_step = 1
        while self.calibration_step == 1 and time.time() - t < 10:
            time.sleep(0.1)

        if len(self.tags) < 5:
            self.err_msg = "Time out, calibrate failed!!!"
            time.sleep(3)
            self.err_msg = None
            self.calibration_step = 0
            self.thread = None
            return

        # calibration of the center position in the recognition area 识别区域中心位置标定
        # calculate the average of multiple recognition data 对多次识别的数据求均值
        pose = map(lambda tag: common.xyz_rot_to_mat(tag.pose_t, tag.pose_R), self.tags) # convert all poses to 4x4 homogeneous matrices 将所有位姿转为4x4齐次矩阵
        vectors = map(lambda p: p.ravel(), pose) # flatten the matrix into a vector 将矩阵展平为向量
        avg_pose = np.mean(list(vectors), axis=0).reshape((4, 4))  # calculate the mean and reassemble into a 4x4 matrix 求均值并重组为4x4矩阵
        self.get_logger().info(f'avg_pose: {avg_pose}')
        pose_end = np.matmul(self.hand2cam_tf_matrix, avg_pose)  # transform to end-effector relative coordinates 转换到末端相对坐标
        self.get_logger().info(f'pose_end: {pose_end}')
        pose_world = np.matmul(endpoint, pose_end)  # transform to robotic arm world coordinates 转换到机械臂世界坐标
        self.get_logger().info(f'pose_world: {pose_world}')
        self.get_logger().info(f'endpoint: {endpoint}')
        self.white_area_pose_world = pose_world
        world_position = np.eye(4)
    
        world_position[:3, 3] = pose_world[:3, 3]
        
        self.white_area_pose_cam = avg_pose
        white_area_pose_cam = avg_pose.tolist()  # the position of the center of the recognition area in the camera's world coordinate system is stored in the parameter 'param' 识别区域中心的在相机的世界坐标系中的位置, 结果存入到param中
        white_area_pose_world = world_position.tolist()  # the position of the center of the recognition area in the camera's world coordinate system is stored in the parameter 'param' 识别区域中心的机械臂世界坐标系的位置, 结果存入到param中

        # extrinsic calibration 外参标定
        world_points = np.array([(-self.tag_size/2, -self.tag_size/2, 0), 
                                 ( self.tag_size/2, -self.tag_size/2, 0), 
                                 ( self.tag_size/2,  self.tag_size/2, 0), 
                                 (-self.tag_size/2,  self.tag_size/2, 0)] * len(self.tags), dtype=np.float64)

        image_points = np.array(list(map(lambda tag: tag.corners, self.tags)), dtype=np.float64).reshape((-1, 2))
        retval, rvec, tvec = cv2.solvePnP(world_points, image_points, self.K, self.D)
        rmat, _ = cv2.Rodrigues(rvec)
        tvec_flattened = tvec.flatten().tolist()

        extristric = [
            tvec_flattened,  # Use tvec as the first row 将 tvec 作为第一行
            rmat[0].tolist(),  # First row of the rotation matrix 第一行的旋转矩阵
            rmat[1].tolist(),  # Second row of the rotation matrix 第二行的旋转矩阵
            rmat[2].tolist()   # Third row of the rotation matrix 第三行的旋转矩阵
        ]
        self.extristric = np.array(extristric)
        corners = self.draw_retangle()
        
        if self.camera_type == "GEMINI":
            data = {
                'white_area_pose_cam': white_area_pose_cam,
                'white_area_pose_world': white_area_pose_world,
                'extristric': extristric,
                'corners': corners.tolist(),
                'plane': self.plane.tolist(),
            }
        if self.camera_type == "USB_CAM":
            data = {
                'white_area_pose_cam': white_area_pose_cam,
                'white_area_pose_world': white_area_pose_world,
                'extristric': extristric,
                'corners': corners.tolist(),
            }

        # self.get_logger().info(f'calibration data: {data}') 
        self.update_yaml_data(data, self.config_path + self.config_file)
        msg = Bool()
        msg.data = True
        self.finish_pub.publish(msg)  
        self.calibration_step = 20
        time.sleep(3)
        self.calibration_step = 0
        self.thread = None

    def send_request(self, client, msg):
        future = client.call_async(msg)
        while rclpy.ok():
            if future.done() and future.result():
                return future.result()

    def update_yaml_data(self, new_data, yaml_file):
        if os.path.exists(yaml_file):
            with open(yaml_file, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)  
        else:
            data = {}  

        data.update(new_data)  

        with open(yaml_file, 'w', encoding='utf-8') as f:
            yaml.dump(data, f)
    
        time.sleep(0.1)

    def start_calibration_srv_callback(self, request, response):
        self.get_logger().info('\033[1;32m%s\033[0m' % "start calibration")
        self.imgpts = None
        self.imgpts1 = None
        self.extristric = None
        self.white_area_pose_cam = None
        self.white_area_pose_world = None
        if self.image_sub is None:
            err_msg = "Please call enter service first"
            self.get_logger().info(str(err_msg))
            response.success = False
            response.message = "stop"
            return response  
        if self.thread is None:
            self.thread = threading.Thread(target=self.calibration_proc)
            self.thread.start()
            response.success = True
            response.message = "start"
            return response
        else:
            msg = "Calibration..."
            self.get_logger().info(msg)
            response.success = False
            response.message = "stop"
            return response

    def enter_srv_callback(self,request, response):
        self.get_logger().info('\033[1;32m%s\033[0m' % "enter calibration")
        # get and publish topic of image 获取和发布图像的topic
        self._init_parameters()
        self.heart = Heart(self, '~/heartbeat', 5, lambda _: self.exit_srv_callback(request=Trigger.Request(), response=Trigger.Response()))  # heartbeat package 心跳包
        if self.camera_type == "GEMINI":
            self.image_sub = self.create_subscription(Image, '/depth_cam/rgb/image_raw', self.image_callback, 1)
            self.camera_info_sub = self.create_subscription(CameraInfo, '/depth_cam/rgb/camera_info', self.camera_info_callback, 1)
            self.depth_image_sub = self.create_subscription(Image, '/depth_cam/depth/image_raw', self.depth_image_callback, 1)
            self.depth_camera_info_sub = self.create_subscription(CameraInfo, '/depth_cam/depth/camera_info', self.depth_camera_info_callback, 1)
        if self.camera_type == "USB_CAM":
            self.image_sub = self.create_subscription(Image, '/image_raw', self.image_callback, 1)
            self.camera_info_sub = self.create_subscription(CameraInfo, '/depth_cam/rgb/camera_info', self.camera_info_callback, 1)
        set_servo_position(self.joints_pub, 1.5, ((1, 500), (2, 520), (3, 210), (4, 50), (5, 500), (10, 200)))  # Set initial position of the robotic arm 设置机械臂初始位置

        self.enter = True
        response.success = True
        response.message = "enter"
        return response

    def exit_srv_callback(self, request, response):
        if self.enter:
            self.get_logger().info('\033[1;32m%s\033[0m' % "exit calibration")
            
            try:
                if self.image_sub is not None:
                    self.destroy_subscription(self.image_sub)
                    self.destroy_subscription(self.camera_info_sub)
                    self.destroy_subscription(self.depth_image_sub)
                    self.destroy_subscription(self.depth_camera_info_sub)
                    self.image_sub = None
                    self.camera_info_sub = None
                    self.depth_image_sub = None
                    self.depth_camera_info_sub = None
            except Exception as e:
                self.get_logger().error(str(e))
            self.heart.destroy()
            self.heart = None
            self.enter = False
        response.success = True
        response.message = "exit"
        return response

    def draw_retangle(self):
        white_area_center = self.white_area_pose_world.reshape(4, 4)
        white_area_cam = self.white_area_pose_cam.reshape(4, 4)
        # self.get_logger().info("white_area_center: {}".format(white_area_center))
        # self.get_logger().info("white_area_cam: {}".format(white_area_cam))
        euler_matrix = common.xyz_euler_to_mat((self.white_area_height / 2, self.white_area_width / 2 + 0.0, 0.0), (0, 0, 0))
        white_area_lt = np.matmul(white_area_center, common.xyz_euler_to_mat((self.white_area_height / 2, self.white_area_width / 2 + 0.0, 0.0), (0, 0, 0)))
        white_area_lb = np.matmul(white_area_center, common.xyz_euler_to_mat((-self.white_area_height / 2, self.white_area_width / 2 + 0.0, 0.0), (0, 0, 0)))
        white_area_rb = np.matmul(white_area_center, common.xyz_euler_to_mat((-self.white_area_height / 2, -self.white_area_width / 2 -0.0, 0.0), (0, 0, 0)))
        white_area_rt = np.matmul(white_area_center, common.xyz_euler_to_mat((self.white_area_height / 2, -self.white_area_width / 2 -0.0, 0.0), (0, 0, 0)))

        endpoint = self.send_request(self.get_current_pose_client, GetRobotPose.Request())
        pose_t = endpoint.pose.position
        pose_r = endpoint.pose.orientation

        endpoint = common.xyz_quat_to_mat([pose_t.x, pose_t.y, pose_t.z], [pose_r.w, pose_r.x, pose_r.y, pose_r.z])
        corners_cam =  np.matmul(np.linalg.inv(np.matmul(endpoint, self.hand2cam_tf_matrix)), [white_area_lt, white_area_lb, white_area_rb, white_area_rt, white_area_center])
        corners_cam = np.matmul(np.linalg.inv(white_area_cam), corners_cam)
        corners_cam = corners_cam[:, :3, 3:].reshape((-1, 3))
        tvec = self.extristric[:1]  
        rmat = self.extristric[1:]  

        while self.K is None or self.D is None:
            time.sleep(0.5)

        center_imgpts, jac = cv2.projectPoints(corners_cam[-1:], np.array(rmat), np.array(tvec), self.K, self.D)
        self.center_imgpts = np.int32(center_imgpts).reshape(2)

        tvec, rmat = common.extristric_plane_shift(np.array(tvec).reshape((3, 1)), np.array(rmat), 0.0)
        imgpts, jac = cv2.projectPoints(corners_cam[:-1], np.array(rmat), np.array(tvec), self.K, self.D)

        self.imgpts = np.int32(imgpts).reshape(-1, 2)
        tvec, rmat = common.extristric_plane_shift(np.array(tvec).reshape((3, 1)), np.array(rmat), 0.04)
        imgpts, jac = cv2.projectPoints(corners_cam[:-1], np.array(rmat), np.array(tvec), self.K, self.D)
        self.imgpts1 = np.int32(imgpts).reshape(-1, 2)
        # self.get_logger().info('corners_cam: {}'.format(corners_cam))
        return corners_cam

    def search_plane(self, depth_image):
        p = self.depth_cam_info.p
        fx = p[0]
        fy = p[5]
        cx = p[2]
        cy = p[6]
        height = self.depth_cam_info.height
        width = self.depth_cam_info.width
        camera_intrinsics = [fx,fy,cx,cy]
        # self.get_logger().info(f'{width}, {height} {camera_intrinsics}')
        searcher = search_plane.SearchPlane(width, height, camera_intrinsics)
        a, m, s = searcher.find_plane(depth_image)
        self.plane = m

    def image_processing(self):
        while self.running:
            if self.enter:
                rgb_image = self.image_queue.get(block=True)
                if self.camera_type == 'GEMINI':
                    depth_image = self.depth_image_queue.get(block=True)
                result_image = np.copy(rgb_image)
                if self.K is not None:
                    tags = self.at_detector.detect(cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY), True, (self.K[0,0], self.K[1,1], self.K[0,2], self.K[1,2]), self.tag_size)
                    result_image = common.draw_tags(result_image, tags)
                    
                    if self.calibration_step == 1:
                        if len(tags) == 1 and (tags[0].tag_id in self.tag_id or tags[0].tag_id == self.tag_id_2):
                            self.err_msg = None
                            if len(self.tags) > 0:
                                if common.distance(self.tags[-1].pose_t, tags[0].pose_t) < 0.003:
                                    self.tags.append(tags[0])
                                else:
                                    self.tags = []
                            else:
                                self.tags.append(tags[0])
                            if len(self.tags) >= 10:
                                print("收集完成")
                                if self.camera_type == 'GEMINI':
                                    if self.depth_cam_info.k is not None:
                                        self.search_plane(depth_image)
                                self.calibration_step = 2
                        else:
                            self.tags = []
                            if self.err_msg is None:
                                self.err_msg = "Please make sure there is only one tag in the;screen and the tag id is 1 or 100"

                    if self.extristric is not None:
                        world_points = np.array([(-self.tag_size/2, -self.tag_size/2, 0),
                                                ( self.tag_size/2, -self.tag_size/2, 0),
                                                ( self.tag_size/2,  self.tag_size/2, 0),
                                                (-self.tag_size/2,  self.tag_size/2, 0)], dtype=np.float64)
                        image_points, _ = cv2.projectPoints(world_points, self.extristric[1:].reshape(3, 3), self.extristric[:1], self.K, self.D)

                        image_points = image_points.astype(np.int32).reshape((-1, 2)).tolist()
                        for p in image_points:
                            cv2.circle(result_image, tuple(p), 3, (0, 0, 0), -1)

                if self.err_msg is not None:
                    self.get_logger().info(str(self.err_msg))
                    err_msg = self.err_msg.split(';')
                    for i, m in enumerate(err_msg):
                        cv2.putText(result_image, m, (5, 50 + (i * 30)), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 6)
                        cv2.putText(result_image, m, (5, 50 + (i * 30)), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)

                if self.calibration_step != 0:
                    if self.calibration_step == 20:
                        msg = "Calibration finished!"
                        self.draw_retangle()
                        cv2.drawContours(result_image, [self.imgpts], -1, (255, 255, 0), 2, cv2.LINE_AA) # draw rectangle 绘制矩形
                    else:
                        msg = "Calibrating..."
                    cv2.putText(result_image, msg, (5, result_image.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 6)
                    cv2.putText(result_image, msg, (5, result_image.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)

                if self.imgpts1 is not None:
                    cv2.drawContours(result_image, [self.imgpts1], -1, (255, 255, 0), 2, cv2.LINE_AA) # draw contours 绘制轮廓
                if self.imgpts is not None:
                    cv2.drawContours(result_image, [self.imgpts], -1, (255, 255, 0), 2, cv2.LINE_AA) # draw rectangle 绘制矩形
                # publish the resulting image 发布结果图像
                self.result_image_pub.publish(self.bridge.cv2_to_imgmsg(result_image, "rgb8"))
            else:
                time.sleep(0.1)

    def camera_info_callback(self, msg):
        self.K = np.matrix(msg.k).reshape(1, -1, 3)
        self.D = np.array(msg.d)

    def depth_camera_info_callback(self, msg):
        self.depth_cam_info = msg

    def image_callback(self, ros_image):
        # convert the ros format image to opencv format 将ros格式图像转换为opencv格式
        cv_image = self.bridge.imgmsg_to_cv2(ros_image, "rgb8")
        rgb_image = np.array(cv_image, dtype=np.uint8)

        if self.image_queue.full():
            # # Discard the oldest image if the queue is full 如果队列已满，丢弃最旧的图像
            self.image_queue.get()
        # # Put image into the queue 将图像放入队列
        self.image_queue.put(rgb_image)

    def depth_image_callback(self, ros_depth_image):
        depth_image = np.ndarray(shape=(ros_depth_image.height, ros_depth_image.width), dtype=np.uint16,
                                 buffer=ros_depth_image.data)

        if self.depth_image_queue.full():
            # # Discard the oldest image if the queue is full 如果队列已满，丢弃最旧的图像
            self.depth_image_queue.get()
        # # Put image into the queue 将图像放入队列
        self.depth_image_queue.put(depth_image)

def main():
    node = CalibrationNode('calibration')
    executor = MultiThreadedExecutor()
    executor.add_node(node)
    try:
        executor.spin()
    except KeyboardInterrupt:
        node.running = False  # Stop thread flag 停止线程标志
        executor.shutdown()
 
if __name__ == "__main__":
    main()
